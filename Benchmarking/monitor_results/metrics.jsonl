{"timestamp": "2025-11-13 18:18:06", "type": "step", "step": 3, "epoch": 0.02666666666666667, "loss": 3.2747, "learning_rate": 4.970501474926254e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.94, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:18:27", "type": "step", "step": 6, "epoch": 0.05333333333333334, "loss": 3.1913, "learning_rate": 4.926253687315635e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:18:47", "type": "step", "step": 9, "epoch": 0.08, "loss": 3.205, "learning_rate": 4.882005899705015e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:19:08", "type": "step", "step": 12, "epoch": 0.10666666666666667, "loss": 3.1959, "learning_rate": 4.8377581120943956e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:19:29", "type": "step", "step": 15, "epoch": 0.13333333333333333, "loss": 3.1327, "learning_rate": 4.7935103244837756e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:19:50", "type": "step", "step": 18, "epoch": 0.16, "loss": 3.119, "learning_rate": 4.749262536873156e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:20:10", "type": "step", "step": 21, "epoch": 0.18666666666666668, "loss": 3.1716, "learning_rate": 4.705014749262537e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:20:31", "type": "step", "step": 24, "epoch": 0.21333333333333335, "loss": 3.197, "learning_rate": 4.660766961651918e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:20:53", "type": "step", "step": 27, "epoch": 0.24, "loss": 3.1052, "learning_rate": 4.6165191740412985e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:21:14", "type": "step", "step": 30, "epoch": 0.26666666666666666, "loss": 3.1863, "learning_rate": 4.5722713864306786e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:21:35", "type": "step", "step": 33, "epoch": 0.29333333333333333, "loss": 3.0462, "learning_rate": 4.528023598820059e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:21:57", "type": "step", "step": 36, "epoch": 0.32, "loss": 3.1153, "learning_rate": 4.48377581120944e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:22:18", "type": "step", "step": 39, "epoch": 0.3466666666666667, "loss": 3.1266, "learning_rate": 4.43952802359882e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:22:39", "type": "step", "step": 42, "epoch": 0.37333333333333335, "loss": 3.1127, "learning_rate": 4.395280235988201e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:23:00", "type": "step", "step": 45, "epoch": 0.4, "loss": 3.1061, "learning_rate": 4.351032448377581e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:23:22", "type": "step", "step": 48, "epoch": 0.4266666666666667, "loss": 3.1413, "learning_rate": 4.306784660766962e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:23:43", "type": "step", "step": 51, "epoch": 0.4533333333333333, "loss": 3.1163, "learning_rate": 4.262536873156342e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:24:04", "type": "step", "step": 54, "epoch": 0.48, "loss": 3.0679, "learning_rate": 4.218289085545723e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:24:26", "type": "step", "step": 57, "epoch": 0.5066666666666667, "loss": 3.1201, "learning_rate": 4.174041297935104e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:24:47", "type": "step", "step": 60, "epoch": 0.5333333333333333, "loss": 3.1625, "learning_rate": 4.129793510324484e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:25:08", "type": "step", "step": 63, "epoch": 0.56, "loss": 3.02, "learning_rate": 4.0855457227138645e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:25:29", "type": "step", "step": 66, "epoch": 0.5866666666666667, "loss": 3.0875, "learning_rate": 4.0412979351032446e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:25:51", "type": "step", "step": 69, "epoch": 0.6133333333333333, "loss": 3.0758, "learning_rate": 3.997050147492625e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:26:12", "type": "step", "step": 72, "epoch": 0.64, "loss": 3.0301, "learning_rate": 3.952802359882006e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:26:33", "type": "step", "step": 75, "epoch": 0.6666666666666666, "loss": 3.1169, "learning_rate": 3.908554572271387e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:26:54", "type": "step", "step": 78, "epoch": 0.6933333333333334, "loss": 3.0435, "learning_rate": 3.8643067846607675e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:27:15", "type": "step", "step": 81, "epoch": 0.72, "loss": 3.082, "learning_rate": 3.8200589970501475e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:27:37", "type": "step", "step": 84, "epoch": 0.7466666666666667, "loss": 3.0098, "learning_rate": 3.775811209439528e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:27:58", "type": "step", "step": 87, "epoch": 0.7733333333333333, "loss": 3.051, "learning_rate": 3.731563421828908e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:28:20", "type": "step", "step": 90, "epoch": 0.8, "loss": 3.0544, "learning_rate": 3.687315634218289e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:28:41", "type": "step", "step": 93, "epoch": 0.8266666666666667, "loss": 3.114, "learning_rate": 3.64306784660767e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:29:02", "type": "step", "step": 96, "epoch": 0.8533333333333334, "loss": 3.0803, "learning_rate": 3.5988200589970505e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:29:24", "type": "step", "step": 99, "epoch": 0.88, "loss": 3.0433, "learning_rate": 3.554572271386431e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:29:46", "type": "step", "step": 102, "epoch": 0.9066666666666666, "loss": 3.0729, "learning_rate": 3.510324483775811e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:30:07", "type": "step", "step": 105, "epoch": 0.9333333333333333, "loss": 3.0583, "learning_rate": 3.466076696165192e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:30:28", "type": "step", "step": 108, "epoch": 0.96, "loss": 3.0306, "learning_rate": 3.421828908554573e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:30:49", "type": "step", "step": 111, "epoch": 0.9866666666666667, "loss": 3.0349, "learning_rate": 3.377581120943953e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:31:09", "type": "step", "step": 114, "epoch": 1.008888888888889, "loss": 2.9872, "learning_rate": 3.3333333333333335e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:31:30", "type": "step", "step": 117, "epoch": 1.0355555555555556, "loss": 2.9948, "learning_rate": 3.2890855457227135e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:31:52", "type": "step", "step": 120, "epoch": 1.0622222222222222, "loss": 3.027, "learning_rate": 3.244837758112095e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:32:13", "type": "step", "step": 123, "epoch": 1.0888888888888888, "loss": 3.0117, "learning_rate": 3.200589970501475e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:32:34", "type": "step", "step": 126, "epoch": 1.1155555555555556, "loss": 3.029, "learning_rate": 3.156342182890856e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
{"timestamp": "2025-11-13 18:32:55", "type": "step", "step": 129, "epoch": 1.1422222222222222, "loss": 3.006, "learning_rate": 3.1120943952802364e-05, "cpu_usage_%": 0.0, "ram_usage_GB": 2.95, "gpu_mem_GB": 0.74, "note": ""}
